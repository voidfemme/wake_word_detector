#!/usr/bin/env python3
# WORKERS OF THE WORLD UNITE âœŠ
from scipy.io.wavfile import write
import asyncio
import io
import numpy as np
import os
import pvporcupine
import resampy
import select
import sounddevice as sd
import sys


class Listener:
    def __init__(self, device=4, sample_rate=48000, channels=1):
        self.device = device
        self.sample_rate = sample_rate
        self.channels = channels
        sd.default.device = self.device  # type: ignore
        sd.default.samplerate = self.sample_rate  # type: ignore
        sd.default.channels = self.channels  # type: ignore
        self.porcupine = self.init_porcupine()
        self.api_key = os.environ["PICOVOICE_API_KEY"]

    def init_porcupine(self):
        porcupine = pvporcupine.create(
            access_key=os.environ["PICOVOICE_API_KEY"],
            keywords=["computer"],
            sensitivities=[0.7],
        )
        return porcupine

    def process_audio_data(self, audio_buffer, sample_rate, wake_word_detected):
        # Resample audio data to match porcupine sample rate
        audio_buffer_resampled = resampy.resample(
            audio_buffer[:, 0], sd.default.samplerate, sample_rate
        )

        # Check that there is enough data to process for wake word detection
        if len(audio_buffer_resampled) >= self.porcupine.frame_length:
            # Save the data in a Pulse Code Modulation format
            pcm = audio_buffer_resampled[: self.porcupine.frame_length].astype(np.int16)

            # Send the data to porcupine for processing
            keyword_index = self.porcupine.process(pcm)
            # keyword_index is >= 0, the wake word has been detected
            if keyword_index >= 0 and not wake_word_detected:
                print("Wake word detected!")
                wake_word_detected = True

        samples_to_remove = (
            self.porcupine.frame_length * audio_buffer.shape[0]
        ) // sample_rate

        # Reset the wake_word_detected variable to False if it has been detected
        if samples_to_remove > 0 and wake_word_detected:
            wake_word_detected = False

        return wake_word_detected, samples_to_remove

    async def recorded_audio_after_wake_word(self, audio_buffer):
        sample_rate = self.porcupine.sample_rate
        frame_length = self.porcupine.frame_length

        recorded_data = []
        recording_duration = 0
        stop_recording = False

        while not stop_recording:
            if len(audio_buffer) >= frame_length:
                recorded_data.append(audio_buffer[:frame_length])
                audio_buffer = audio_buffer[frame_length:]

            await asyncio.sleep(0.02)
            recording_duration += 0.02

            if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
                line = input()
                if line == "q":
                    stop_recording = True

        recorded_audio = np.concatenate(recorded_data, axis=0)
        return recorded_audio

    async def listen_for_wake_word(self):
        sample_rate = self.porcupine.sample_rate
        frame_length = self.porcupine.frame_length

        audio_buffer = np.zeros((0, 1), dtype="int16")
        recorded_data = []
        stop_listening = False
        recording_duration = 0
        wake_word_detected = False

        def audio_callback(indata, frames, time, status):
            nonlocal audio_buffer
            audio_buffer = np.concatenate((audio_buffer, indata.copy()), axis=0)

        with sd.InputStream(
            callback=audio_callback, blocksize=frame_length, dtype="int16"
        ):
            while not stop_listening:
                if len(audio_buffer) >= self.porcupine.frame_length:
                    wake_word_detected, samples_to_remove = self.process_audio_data(
                        audio_buffer, sample_rate, wake_word_detected
                    )

                    audio_buffer = audio_buffer[samples_to_remove:]

                    if wake_word_detected:
                        recorded_data.append(audio_buffer[:samples_to_remove])

                await asyncio.sleep(0.02)

                if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
                    line = input()
                    if line == "q":
                        break

                if wake_word_detected:
                    recorded_audio = await self.recorded_audio_after_wake_word(
                        audio_buffer
                    )
                    return recorded_audio

            return np.array([])

    def audio_to_bytestream(self, recorded_audio):
        byte_stream = io.BytesIO()
        write(byte_stream, sd.default.samplerate, recorded_audio)
        byte_stream.seek(0)
        return byte_stream

    def run(self):
        try:
            print("Listening for wake word...")
            recorded_audio = self.listen_for_wake_word()
            print("Saving recorded audio...")
            audio_data = self.audio_to_bytestream(recorded_audio)
            return audio_data
        finally:
            if self.porcupine is not None:
                self.porcupine.delete()

    async def run_async(self):
        try:
            print("Listening for wake word...")
            recorded_audio = await self.listen_for_wake_word()
            if recorded_audio.size > 0:
                print("Saving recorded audio...")
                file_name = "recorded_audio.wav"
                write(file_name, sd.default.samplerate, recorded_audio)
                print(f"Recorded audio saved to {file_name}")
            else:
                print("No audio was recorded")
            return audio_data
        finally:
            if self.porcupine is not None:
                self.porcupine.delete()


if __name__ == "__main__":
    wake_word_recorder = Listener()
    loop = asyncio.get_event_loop()
    audio_data = loop.run_until_complete(wake_word_recorder.run_async())
